{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69a04d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f74f6ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import dataset\n",
    "df_train = pd.read_csv(\"train.csv\")\n",
    "df_test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "345cd536",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check dataset\n",
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c947bf4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "#check dataset\n",
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb9a5839",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_survived = df_train['Survived']\n",
    "df_train = df_train.drop(['PassengerId', 'Survived', 'Ticket', 'Cabin'],axis=1)\n",
    "df_test_id = df_test['PassengerId']\n",
    "df_test = df_test.drop(['PassengerId', 'Ticket', 'Cabin'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52388109",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pclass        0\n",
       "Name          0\n",
       "Sex           0\n",
       "Age         177\n",
       "SibSp         0\n",
       "Parch         0\n",
       "Fare          0\n",
       "Embarked      2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d117ed5",
   "metadata": {},
   "source": [
    "# Extract title from name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "689acdaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = [df_train, df_test]\n",
    "\n",
    "for df in dataframe:\n",
    "    df['Title'] = df['Name'].str.split(', ').str[1]\n",
    "    df['Title'] = df['Title'].str.split('.').str[0]\n",
    "    \n",
    "df_train = df_train.drop(['Name'],axis=1)\n",
    "df_test = df_test.drop(['Name'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14777dc",
   "metadata": {},
   "source": [
    "# Change values in Sex to numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92566f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = [df_train, df_test]\n",
    "\n",
    "for df in dataframe:\n",
    "    df['Sex'] = df['Sex'].replace({'female':0, 'male':1})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92216fa",
   "metadata": {},
   "source": [
    "# Title Grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d60266fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_titles(x):\n",
    "    title=x['Title']\n",
    "    if title in ['Don', 'Major', 'Capt', 'Jonkheer', 'Rev', 'Col', 'Sir']:\n",
    "        return 'Mr'\n",
    "    elif title in ['the Countess', 'Mme', 'Lady', 'Dona']:\n",
    "        return 'Mrs'\n",
    "    elif title in ['Mlle', 'Ms']:\n",
    "        return 'Miss'\n",
    "    elif title =='Dr':\n",
    "        if x['Sex']=='Male':\n",
    "            return 'Mr'\n",
    "        else:\n",
    "            return 'Mrs'\n",
    "    else:\n",
    "        return title\n",
    "\n",
    "dataframe = [df_train, df_test]\n",
    "\n",
    "for df in dataframe:\n",
    "    df['Title'] = df.apply(replace_titles, axis=1)\n",
    "    df['Title'] = df['Title'].replace({'Mr':0, 'Mrs':1, 'Miss':2, 'Master':3})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65fd7d65",
   "metadata": {},
   "source": [
    "# Change values in Embarked to numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "778937b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['S', 'C', 'Q', nan], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['Embarked'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1be1758",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = [df_train, df_test]\n",
    "\n",
    "for df in dataframe:\n",
    "    df['Embarked'] = df['Embarked'].replace({'S':0, 'C':1, 'Q':2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53be5d39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Pclass</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.131900</td>\n",
       "      <td>-0.369226</td>\n",
       "      <td>0.083081</td>\n",
       "      <td>0.018443</td>\n",
       "      <td>-0.549500</td>\n",
       "      <td>0.043835</td>\n",
       "      <td>-0.025429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <td>0.131900</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.093254</td>\n",
       "      <td>-0.114631</td>\n",
       "      <td>-0.245489</td>\n",
       "      <td>-0.182333</td>\n",
       "      <td>-0.118593</td>\n",
       "      <td>-0.692582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>-0.369226</td>\n",
       "      <td>0.093254</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.308247</td>\n",
       "      <td>-0.189119</td>\n",
       "      <td>0.096067</td>\n",
       "      <td>0.012186</td>\n",
       "      <td>-0.432974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SibSp</th>\n",
       "      <td>0.083081</td>\n",
       "      <td>-0.114631</td>\n",
       "      <td>-0.308247</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.414838</td>\n",
       "      <td>0.159651</td>\n",
       "      <td>-0.060606</td>\n",
       "      <td>0.324305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parch</th>\n",
       "      <td>0.018443</td>\n",
       "      <td>-0.245489</td>\n",
       "      <td>-0.189119</td>\n",
       "      <td>0.414838</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.216225</td>\n",
       "      <td>-0.079320</td>\n",
       "      <td>0.339626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare</th>\n",
       "      <td>-0.549500</td>\n",
       "      <td>-0.182333</td>\n",
       "      <td>0.096067</td>\n",
       "      <td>0.159651</td>\n",
       "      <td>0.216225</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.063462</td>\n",
       "      <td>0.153547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embarked</th>\n",
       "      <td>0.043835</td>\n",
       "      <td>-0.118593</td>\n",
       "      <td>0.012186</td>\n",
       "      <td>-0.060606</td>\n",
       "      <td>-0.079320</td>\n",
       "      <td>0.063462</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.128561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Title</th>\n",
       "      <td>-0.025429</td>\n",
       "      <td>-0.692582</td>\n",
       "      <td>-0.432974</td>\n",
       "      <td>0.324305</td>\n",
       "      <td>0.339626</td>\n",
       "      <td>0.153547</td>\n",
       "      <td>0.128561</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Pclass       Sex       Age     SibSp     Parch      Fare  \\\n",
       "Pclass    1.000000  0.131900 -0.369226  0.083081  0.018443 -0.549500   \n",
       "Sex       0.131900  1.000000  0.093254 -0.114631 -0.245489 -0.182333   \n",
       "Age      -0.369226  0.093254  1.000000 -0.308247 -0.189119  0.096067   \n",
       "SibSp     0.083081 -0.114631 -0.308247  1.000000  0.414838  0.159651   \n",
       "Parch     0.018443 -0.245489 -0.189119  0.414838  1.000000  0.216225   \n",
       "Fare     -0.549500 -0.182333  0.096067  0.159651  0.216225  1.000000   \n",
       "Embarked  0.043835 -0.118593  0.012186 -0.060606 -0.079320  0.063462   \n",
       "Title    -0.025429 -0.692582 -0.432974  0.324305  0.339626  0.153547   \n",
       "\n",
       "          Embarked     Title  \n",
       "Pclass    0.043835 -0.025429  \n",
       "Sex      -0.118593 -0.692582  \n",
       "Age       0.012186 -0.432974  \n",
       "SibSp    -0.060606  0.324305  \n",
       "Parch    -0.079320  0.339626  \n",
       "Fare      0.063462  0.153547  \n",
       "Embarked  1.000000  0.128561  \n",
       "Title     0.128561  1.000000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc5e823",
   "metadata": {},
   "source": [
    "# Handling missing values using MICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "48364c33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\guntur.althair\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n"
     ]
    }
   ],
   "source": [
    "# Handling missing values in df_train\n",
    "# need to enable iterative imputer explicitly since its still experimental\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "# Define imputer\n",
    "imputer = IterativeImputer(random_state=100, max_iter=10)\n",
    "\n",
    "# Use Numeric Features\n",
    "df_train_impute = df_train[['Sex', 'Age', 'Fare', 'Embarked']]\n",
    "df_test_impute = df_test[['Sex', 'Age', 'Fare', 'Embarked']]\n",
    "\n",
    "# fit on the dataset\n",
    "imputer.fit(df_train_impute)\n",
    "imputer.fit(df_test_impute)\n",
    "\n",
    "df_imputed_train = imputer.transform(df_train_impute)\n",
    "df_imputed_train[:10]\n",
    "df_imputed_test = imputer.transform(df_test_impute)\n",
    "df_imputed_test[:10]\n",
    "\n",
    "\n",
    "# Replace with imputed values\n",
    "df_train_impute.loc[:,:] = df_imputed_train\n",
    "df_test_impute.loc[:,:] = df_imputed_test\n",
    "\n",
    "\n",
    "# Fill nan values in df_train\n",
    "df_train = df_train.fillna(df_train_impute)\n",
    "df_test = df_test.fillna(df_test_impute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ad755766",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Int Age and Embarked\n",
    "dataframe = [df_train, df_test]\n",
    "\n",
    "for df in dataframe:\n",
    "    df['Age'] = df['Age'].astype(int)\n",
    "    df['Embarked'] = df['Embarked'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd203f4",
   "metadata": {},
   "source": [
    "# Create Pclass dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "62a536e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummies for train\n",
    "pclass_columns = pd.get_dummies(df_train['Pclass'])\n",
    "Pclass_1 = pclass_columns.loc[:,1:1].max(axis=1)\n",
    "Pclass_2 = pclass_columns.loc[:,2:2].max(axis=1)\n",
    "Pclass_3 = pclass_columns.loc[:,3:3].max(axis=1)\n",
    "df_train = pd.concat([df_train, Pclass_1, Pclass_2,Pclass_3], axis=1)\n",
    "\n",
    "# Create dummies for test\n",
    "pclass_columns = pd.get_dummies(df_test['Pclass'])\n",
    "Pclass_1 = pclass_columns.loc[:,1:1].max(axis=1)\n",
    "Pclass_2 = pclass_columns.loc[:,2:2].max(axis=1)\n",
    "Pclass_3 = pclass_columns.loc[:,3:3].max(axis=1)\n",
    "df_test = pd.concat([df_test, Pclass_1, Pclass_2,Pclass_3], axis=1)\n",
    "\n",
    "# Rename columns\n",
    "dataframe = [df_train, df_test]\n",
    "\n",
    "for df in dataframe:\n",
    "    df.rename(columns = {0:'Pclass_1', 1:'Pclass_2', 2:'Pclass_3'}, inplace = True)\n",
    "    \n",
    "df_train = df_train.drop(['Pclass'],axis=1)\n",
    "df_test = df_test.drop(['Pclass'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4442c81",
   "metadata": {},
   "source": [
    "# Create Title dummies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ac20a536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummies for train\n",
    "title_columns = pd.get_dummies(df_train['Title'])\n",
    "Mr = title_columns.loc[:,0:0].max(axis=1)\n",
    "Mrs = title_columns.loc[:,1:1].max(axis=1)\n",
    "Miss = title_columns.loc[:,2:2].max(axis=1)\n",
    "Master = title_columns.loc[:,3:3].max(axis=1)\n",
    "df_train = pd.concat([df_train, Mr, Mrs, Miss, Master], axis=1)\n",
    "\n",
    "# Create dummies for test\n",
    "title_columns = pd.get_dummies(df_test['Title'])\n",
    "Mr = title_columns.loc[:,0:0].max(axis=1)\n",
    "Mrs = title_columns.loc[:,1:1].max(axis=1)\n",
    "Miss = title_columns.loc[:,2:2].max(axis=1)\n",
    "Master = title_columns.loc[:,3:3].max(axis=1)\n",
    "df_test = pd.concat([df_test, Mr, Mrs, Miss, Master], axis=1)\n",
    "\n",
    "# Rename columns\n",
    "dataframe = [df_train, df_test]\n",
    "\n",
    "for df in dataframe:\n",
    "    df.rename(columns = {0:'Mr', 1:'Mrs', 2:'Miss', 3:'Master'}, inplace = True)\n",
    "    \n",
    "df_train = df_train.drop(['Title'],axis=1)\n",
    "df_test = df_test.drop(['Title'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734c0b2f",
   "metadata": {},
   "source": [
    "# Create Embarked dummies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "711b8e02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['Embarked'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dcf3d840",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummies for train\n",
    "embarked_columns = pd.get_dummies(df_train['Embarked'])\n",
    "S = embarked_columns.loc[:,0:0].max(axis=1)\n",
    "C = embarked_columns.loc[:,1:1].max(axis=1)\n",
    "Q = embarked_columns.loc[:,2:2].max(axis=1)\n",
    "df_train = pd.concat([df_train, S, C, Q], axis=1)\n",
    "\n",
    "# Create dummies for test\n",
    "embarked_columns = pd.get_dummies(df_test['Embarked'])\n",
    "S = embarked_columns.loc[:,0:0].max(axis=1)\n",
    "C = embarked_columns.loc[:,1:1].max(axis=1)\n",
    "Q = embarked_columns.loc[:,2:2].max(axis=1)\n",
    "df_test = pd.concat([df_test, S, C, Q], axis=1)\n",
    "\n",
    "# Rename columns\n",
    "dataframe = [df_train, df_test]\n",
    "\n",
    "for df in dataframe:\n",
    "    df.rename(columns = {0:'S', 1:'C', 2:'Q'}, inplace = True)\n",
    "    \n",
    "df_train = df_train.drop(['Embarked'],axis=1)\n",
    "df_test = df_test.drop(['Embarked'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "27a39d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train1 = df_train.copy()\n",
    "df_test1 = df_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aab3c0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train1.copy()\n",
    "df_test = df_test1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "80bf1a86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 15 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Sex       891 non-null    int64  \n",
      " 1   Age       891 non-null    int32  \n",
      " 2   SibSp     891 non-null    int64  \n",
      " 3   Parch     891 non-null    int64  \n",
      " 4   Fare      891 non-null    float64\n",
      " 5   Pclass_1  891 non-null    uint8  \n",
      " 6   Pclass_2  891 non-null    uint8  \n",
      " 7   Pclass_3  891 non-null    uint8  \n",
      " 8   Mr        891 non-null    uint8  \n",
      " 9   Mrs       891 non-null    uint8  \n",
      " 10  Miss      891 non-null    uint8  \n",
      " 11  Master    891 non-null    uint8  \n",
      " 12  S         891 non-null    uint8  \n",
      " 13  C         891 non-null    uint8  \n",
      " 14  Q         891 non-null    uint8  \n",
      "dtypes: float64(1), int32(1), int64(3), uint8(10)\n",
      "memory usage: 40.2 KB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1f156359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 15 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Sex       418 non-null    int64  \n",
      " 1   Age       418 non-null    int32  \n",
      " 2   SibSp     418 non-null    int64  \n",
      " 3   Parch     418 non-null    int64  \n",
      " 4   Fare      418 non-null    float64\n",
      " 5   Pclass_1  418 non-null    uint8  \n",
      " 6   Pclass_2  418 non-null    uint8  \n",
      " 7   Pclass_3  418 non-null    uint8  \n",
      " 8   Mr        418 non-null    uint8  \n",
      " 9   Mrs       418 non-null    uint8  \n",
      " 10  Miss      418 non-null    uint8  \n",
      " 11  Master    418 non-null    uint8  \n",
      " 12  S         418 non-null    uint8  \n",
      " 13  C         418 non-null    uint8  \n",
      " 14  Q         418 non-null    uint8  \n",
      "dtypes: float64(1), int32(1), int64(3), uint8(10)\n",
      "memory usage: 18.9 KB\n"
     ]
    }
   ],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c119c56",
   "metadata": {},
   "source": [
    "# Build Machine Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "df813388",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train\n",
    "Y_train = df_train_survived\n",
    "X_test  = df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41087b0a",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4ce8391a",
   "metadata": {},
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "random_forest = RandomForestClassifier(n_estimators=100, oob_score=True)\n",
    "random_forest.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = random_forest.predict(X_test)\n",
    "random_forest.score(X_train, Y_train)\n",
    "acc_random_forest = round(random_forest.score(X_train, Y_train) * 100, 2)\n",
    "\n",
    "oob_error = 1-random_forest.oob_score_"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9f562c68",
   "metadata": {},
   "source": [
    "print(f\"oob error: {oob_error:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd09d29",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f880a06f",
   "metadata": {},
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, Y_train)\n",
    "Y_pred = logreg.predict(X_test)\n",
    "acc_log = round(logreg.score(X_train, Y_train) * 100, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21756ace",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "raw",
   "id": "44af7aaa",
   "metadata": {},
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = 3)\n",
    "knn.fit(X_train, Y_train)\n",
    "Y_pred = knn.predict(X_test)\n",
    "acc_knn = round(knn.score(X_train, Y_train) * 100, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e0b54d",
   "metadata": {},
   "source": [
    "# Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6223a54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "gaussian = GaussianNB()\n",
    "gaussian.fit(X_train, Y_train)\n",
    "Y_pred = gaussian.predict(X_test)  \n",
    "acc_gaussian = round(gaussian.score(X_train, Y_train) * 100, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a52053f",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bebaab84",
   "metadata": {},
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "decision_tree = DecisionTreeClassifier() \n",
    "decision_tree.fit(X_train, Y_train) \n",
    "Y_pred = decision_tree.predict(X_test)\n",
    "acc_decision_tree = round(decision_tree.score(X_train, Y_train) * 100, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0ba8ab",
   "metadata": {},
   "source": [
    "# Models Score"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6a8b9587",
   "metadata": {},
   "source": [
    "models = pd.DataFrame({\n",
    "    'Model': ['Random Forest', 'Logistic Regression', 'KNN', 'Gaussian Naive Bayes', 'Decision Tree'],\n",
    "    'Score': [acc_random_forest, acc_log, acc_knn, acc_gaussian, acc_decision_tree]})\n",
    "models.sort_values(by='Score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eda4eda2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[448, 101],\n",
       "       [ 78, 264]], dtype=int64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "predictions = cross_val_predict(gaussian, X_train, Y_train, cv=3)\n",
    "confusion_matrix(Y_train, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "93a62cb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.7232876712328767\n",
      "Recall: 0.7719298245614035\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "print(\"Precision:\", precision_score(Y_train, predictions))\n",
    "print(\"Recall:\",recall_score(Y_train, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f8cadeda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7468175388967468"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(Y_train, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c0912518",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame({\n",
    "    'PassengerId': df_test_id,\n",
    "    'Survived': Y_pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f09d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result.to_csv('Titanic-althair.guntur.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58f88be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
